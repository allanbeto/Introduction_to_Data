---
title: "Introduction of Data"
author: "AAA"
date: "17 de diciembre de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Course Description
Scientists seek to answer questions using rigorous methods and careful observations. These observations—collected from the likes of field notes, surveys, and experiments—form the backbone of a statistical investigation and are called data. Statistics is the study of how best to collect, analyze, and draw conclusions from data. It is helpful to put statistics in the context of a general process of investigation: 1) identify a question or problem; 2) collect relevant data on the topic; 3) analyze the data; and 4) form a conclusion. In this course, you'll focus on the first two steps of the process.


## Language of data
This chapter introduces terminology of datasets and data frames in R.

```{r}
##pre_code
# install.packages("openintro")
# install.packages("dplyr")
# install.packages("ggplot2")

library("openintro")
library("dplyr")
library("ggplot2")

```

```{r}
# Load data
data(email50)

# View its structure
str(email50)
```

### Identify variable types

Recall from the video that the glimpse() function from dplyr provides a handy alternative to str() for previewing a dataset. In addition to telling you the number of observations and variables, it shows the name and type of each column, along with a neatly printed preview of its values.

Let's have another look at the email50 data, so you can practice identifying variable types.

### INSTRUCTIONS

Use the glimpse() function to view the variables in the email50 dataset. Identify each variable as either numerical or categorical, and further as discrete or continuous (if numerical) or ordinal or not ordinal (if categorical).

```{r}
# Glimpse email50
glimpse(email50)
```


### Filtering based on a factor

Categorical data are often stored as factors in R. In this exercise, you'll get some practice working with a factor variable, number, from the email50 dataset. This variable tells you what type of number (none, small, or big) an email contains.

Recall from the video that the filter() function from dplyr allows you to filter a dataset to create a subset containing only certain levels of a variable. For example, the following code filters the mtcars dataset for cars containing 6 cylinders:

mtcars %>%
  filter(cyl == 6)

### INSTRUCTIONS

Create a new dataset called email50_big that is a subset of the original email50 dataset containing only emails with "big" numbers. This information is stored in the number variable.
Report the dimensions of email50_big using the glimpse() function again. How many emails contain big numbers?

```{r}
# Subset of emails with big numbers: email50_big
email50_big <- email50 %>%
  filter(number=="big")

# Glimpse the subset
glimpse(email50_big)
```

### Complete filtering based on a factor

The droplevels() function removes unused levels of factor variables from your dataset. As you saw in the video, it's often useful to determine which levels are unused (i.e. contain zero values) with the table() function.

In this exercise, you'll see which levels of the number variable are dropped after applying the droplevels() function.

### INSTRUCTIONS

Make a table() of the number variable in the email50_big dataset. Which two levels are unused?
Apply the droplevels() function to the number variable. Assign the result back to email50_big$number.
Remake the table() of the number variable in the email50_big dataset. How is this output different from the first?

```{r}
# Table of number variable
table(email50_big$number)

# Drop levels
email50_big$number <- droplevels(email50_big$number)

# Another table of number variable
table(email50_big$number)
```

### Discretize a different variable

In this exercise, you will create a categorical version of the num_char variable in the email50 dataset, which tells you the number of characters in an email, in thousands. This new variable will have two levels—"below median" and "at or above median"—depending on whether an email has less than the median number of characters or equal to or more than that value.

The median marks the 50th percentile, or midpoint, of a distribution, so half of the emails should fall in one category and the other half in the other. You will learn more about the median and other measures of center in the next course in this series.

### INSTRUCTIONS

The email50 dataset is available in your workspace.

Use the num_char variable to find the median number of characters in the emails and store the result as med_num_char.
Create a new variable called num_char_cat, which discretizes the num_char variable into "below median" or "at or above median". Use the mutate() function from dplyr to accomplish this.
Apply table() on this new variable num_char_cat to determine how many emails are in each category and evaluate whether these counts match the expected numbers.

```{r}
# Calculate median number of characters: med_num_char
med_num_char <- median(email50$num_char)

# Create num_char_cat variable in email50
email50 <- email50 %>%
  mutate(num_char_cat = ifelse(num_char < med_num_char, "below median", "at or above median"))
  
# Count emails in each category
table(email50$num_char_cat)
```

### Combining levels of a different factor

Another common way of creating a new variable based on an existing one is by combining levels of a categorical variable. For example, the email50 dataset has a categorical variable called number with levels "none", "small", and "big", but suppose you're only interested in whether an email contains a number. In this exercise, you will create a variable containing this information and also visualize it.

For now, do your best to understand the code we've provided to generate the plot. We will go through it in detail in the next video.

### INSTRUCTIONS

Create a new variable in email50 called number_yn that is "no" if there is no number in the email and "yes" if there is a small or a big number. The ifelse() function may prove useful here.
Run the code provided to visualize the distribution of the number_yn variable.


```{r}
# Create number_yn column in email50
email50 <- email50 %>%
  mutate(number_yn = ifelse(number == "none", "no", "yes"))

# Visualize number_yn
ggplot(email50, aes(x = number_yn)) +
  geom_bar()
```

### Visualizing numerical and categorical data

In this exercise, you will visualize the relationship between two numerical variables from the email50 dataset, conditioned on whether or not the email was spam. This means that we will use some aspect of the plot (like color or shape) to separate the groups in the spam column so that we can compare plotted values between them.

Recall that in the ggplot() function, the first argument gives the dataset, then the aesthetics map the variables to certain features of the plot, and finally the geom_*() layer informs the type of plot you want to make. In this exercise, you will make a scatterplot by adding the geom_point() layer to your ggplot() call.

### INSTRUCTIONS

Create a scatterplot of number of exclamation points in the email message (exclaim_mess) vs. number of characters (num_char).

Color points by whether or not the email is spam.
Note that the spam variable is stored as numerical (0/1) but you want to use it as a categorical variable in this plot. To do this, you need to force R to think of it as such with the factor() function.
Based on the plot, what's the relationship between these variables?


```{r}
# Load ggplot2
library(ggplot2)

# Scatterplot of exclaim_mess vs. num_char
ggplot(email50, aes(x =num_char , y =exclaim_mess , color = factor(spam))) +
  geom_point()
```

## Study types and cautionary tales
In this chapter, you will learn about observational studies and experiments, scope of inference, and Simpson's paradox.


### Identify study type

A study is designed to evaluate whether people read text faster in Arial or Helvetica font. A group of volunteers who agreed to be a part of the study are randomly assigned to two groups: one where they read some text in Arial, and another where they read the same text in Helvetica. At the end, average reading speeds from the two groups are compared.

What type of study is this?   Experiment
Identify the type of study

Next, let's take a look at data from a different study on country characteristics. You'll load the data first and view it, then you'll be asked to identify the type of study. Remember, an experiment requires random assignment.

### INSTRUCTIONS

Load the gapminder data. This dataset comes from the gapminder R package, which has already been loaded for you.
View the variables in the dataset with glimpse().
If these data come from an observational study, assign "observational" to the type_of_study variable. If experimental, assign "experimental".

```{r}
### Pre-code
#install.packages("gapminder")

library("gapminder")

# Load data
data(gapminder)

# Glimpse data
glimpse(gapminder)

# Identify type of study
type_of_study <- "observational"

```

### Random sampling or random assignment?

One of the early studies linking smoking and lung cancer compared patients who are already hospitalized with lung cancer to similar patients without lung cancer (hospitalized for other reasons), and recorded whether each patient smoked. Then, proportions of smokers for patients with and without lung cancer were compared.

Does this study employ random sampling and/or random assignment?

Neither random sampling nor random assignment

### Identify the scope of inference of study

Volunteers were recruited to participate in a study where they were asked to type 40 bits of trivia—for example, "an ostrich’s eye is bigger than its brain"—into a computer. A randomly selected half of these subjects were told the information would be saved in the computer; the other half were told the items they typed would be erased.

Then, the subjects were asked to remember these bits of trivia, and the number of bits of trivia each subject could correctly recall were recorded. It was found that the subjects were significantly more likely to remember information if they thought they would not be able to find it later.

The results of the study ___ be generalized to all people and a causal link between believing information is stored and memory ___ be inferred based on these results.

Answer ---- cannot, can

### Number of males and females admitted

In order to calculate the number of males and females admitted, we will introduce two new functions: count() from the dplyr package and spread() from the tidyr package.

In one step, count() allows you to group the data by certain variables (in this case, admission status and gender) and then counts the number of observations in each category. These counts are available under a new variable called n.

spread() simply reorganizes the output across columns based on a key-value pair, where a pair contains a key that explains what the information describes and a value that contains the actual information. spread() takes the name of the dataset as its first argument, the name of the key column as its second argument, and the name of the value column as its third argument, all specified without quotation marks.

### INSTRUCTIONS

Use the ucb_admit dataset (which is already pre-loaded) and the count() function to determine the total number of males and females admitted. Assign the result to ucb_counts.
Print ucb_counts to the console.
Then, use the spread() function to spread the output across columns based on admission status (key) and n (value).
```{r}
## pre-code
install.packages("tidyr")

url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_2331/datasets/ucb_admit.RData"

download.file(url, "ucb_admit.RData")

load(ucb_admit.RData)


```

```{r}




# Load packages
library(dplyr)
library(tidyr)

# Count number of male and female applicants admitted
ucb_counts <- ucb_admit %>%
  count(Admit, Gender)

# View result
ucb_counts
  
# Spread the output across columns
ucb_counts %>%
  spread(Admit, n)
```







## Sampling strategies and experimental design
This chapter defines various sampling strategies and their benefits/drawbacks as well as principles of experimental design.


## Case study
Apply terminology, principles, and R code learned in the first three chapters of this course to a case study looking at how the physical appearance of instructors impacts their students' course evaluations.






